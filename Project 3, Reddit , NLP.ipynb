{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\reza\\\\Desktop\\\\dsi\\\\Projects\\\\project_3'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**START**: There is some markets aound where we can look for safe and healthy produces that free of meat.\n",
    "Using Natural Language Processing I think of a model to develop to identify the people who are trying to use free meat produces. How many posts and comments are online for vegan. Finally the model will optimize Specificity.\n",
    "I will work on all models I know and I have enough information about those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reza\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply all information based on Sir Reily YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.pushshift.io/reddit/search/submission\"\n",
    "\n",
    "# submit a base url with a dictionary of parameters;\n",
    "params = {\"subreddit\":\"Vegeterian\",                                       # name of the subreddit\n",
    "           \"size\":500,                                                     # default size is 25, max value is 500\n",
    "          \"before\": None}                                                 # data before timestamp                     \n",
    "\n",
    "res = requests.get(url, params)\n",
    "\n",
    "res.status_code\n",
    "\n",
    "data = res.json()\n",
    "\n",
    "posts = data['data']\n",
    "posts\n",
    "\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose two subreddits: 1. Vegetarian,  2. Vegan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Subreddit = Vegetarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "last = ''\n",
    "posts_list = []\n",
    "\n",
    "url='https://api.pushshift.io/reddit/search/submission/?subreddit=Vegetarian'\n",
    "\n",
    "while n < 10000:\n",
    "    request = requests.get('{}&before={}'.format(url, last))\n",
    "    json = request.json()\n",
    "    for post in json['data']:\n",
    "        posts_list.append(post)\n",
    "        n += 1\n",
    "last = int(post['created_utc'])\n",
    "print(request.status_code)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegi_df = pd.DataFrame(posts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I attempted Yeast Free Naan! Paneer Masala and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question about Vitamin A Palamite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach Pesto with Seared Tomatoes and Shaved ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  I attempted Yeast Free Naan! Paneer Masala and...\n",
       "1                  Question about Vitamin A Palamite\n",
       "2  Spinach Pesto with Seared Tomatoes and Shaved ..."
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegi_df[['title']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I attempted Yeast Free Naan! Paneer Masala and...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question about Vitamin A Palamite</td>\n",
       "      <td>I've been vegetarian for a bit, and I know to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach Pesto with Seared Tomatoes and Shaved ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I attempted Yeast Free Naan! Paneer Masala and...   \n",
       "1                  Question about Vitamin A Palamite   \n",
       "2  Spinach Pesto with Seared Tomatoes and Shaved ...   \n",
       "\n",
       "                                            selftext  \n",
       "0                                                     \n",
       "1  I've been vegetarian for a bit, and I know to ...  \n",
       "2                                                     "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegi_df[['title', 'selftext']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I attempted Yeast Free Naan! Paneer Masala and...</td>\n",
       "      <td></td>\n",
       "      <td>vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question about Vitamin A Palamite</td>\n",
       "      <td>I've been vegetarian for a bit, and I know to ...</td>\n",
       "      <td>vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach Pesto with Seared Tomatoes and Shaved ...</td>\n",
       "      <td></td>\n",
       "      <td>vegetarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I attempted Yeast Free Naan! Paneer Masala and...   \n",
       "1                  Question about Vitamin A Palamite   \n",
       "2  Spinach Pesto with Seared Tomatoes and Shaved ...   \n",
       "\n",
       "                                            selftext   subreddit  \n",
       "0                                                     vegetarian  \n",
       "1  I've been vegetarian for a bit, and I know to ...  vegetarian  \n",
       "2                                                     vegetarian  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegi_df[['title', 'selftext', 'subreddit']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vegetarian    10000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegi_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegi_df = vegi_df[['title', 'selftext', \"subreddit\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Subreddit = Vegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "last = ''\n",
    "posts_list = []\n",
    "\n",
    "url='https://api.pushshift.io/reddit/search/submission/?subreddit=Vegan'\n",
    "\n",
    "while n < 10000:\n",
    "    request = requests.get('{}&before={}'.format(url, last))\n",
    "    json = request.json()\n",
    "    for post in json['data']:\n",
    "        posts_list.append(post)\n",
    "        n += 1\n",
    "last = int(post['created_utc'])\n",
    "print(request.status_code)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_df = pd.DataFrame(posts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Business Name Ideas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I discovered the trick to easily getting all o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yummmyyy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0                           Food Business Name Ideas\n",
       "1  I discovered the trick to easily getting all o...\n",
       "2                                           Yummmyyy"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_df[['title']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Business Name Ideas</td>\n",
       "      <td>I am thinking of putting up a vegan food deliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I discovered the trick to easily getting all o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yummmyyy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                           Food Business Name Ideas   \n",
       "1  I discovered the trick to easily getting all o...   \n",
       "2                                           Yummmyyy   \n",
       "\n",
       "                                            selftext  \n",
       "0  I am thinking of putting up a vegan food deliv...  \n",
       "1                                                     \n",
       "2                                                     "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_df[['title', 'selftext']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>PETA isn't the savior you think it is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>It’s not racism or anything like that</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Could we be more of a plague to this planet?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title   selftext\n",
       "9997         PETA isn't the savior you think it is           \n",
       "9998         It’s not racism or anything like that  [removed]\n",
       "9999  Could we be more of a plague to this planet?           "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_df[['title', 'selftext']].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Business Name Ideas</td>\n",
       "      <td>I am thinking of putting up a vegan food deliv...</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I discovered the trick to easily getting all o...</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yummmyyy</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                           Food Business Name Ideas   \n",
       "1  I discovered the trick to easily getting all o...   \n",
       "2                                           Yummmyyy   \n",
       "\n",
       "                                            selftext subreddit  \n",
       "0  I am thinking of putting up a vegan food deliv...     vegan  \n",
       "1                                                        vegan  \n",
       "2                                                        vegan  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_df[['title', 'selftext', 'subreddit']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vegan    10000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_df = vegan_df[['title', 'selftext', \"subreddit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([vegi_df, vegan_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I attempted Yeast Free Naan! Paneer Masala and...</td>\n",
       "      <td></td>\n",
       "      <td>vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question about Vitamin A Palamite</td>\n",
       "      <td>I've been vegetarian for a bit, and I know to ...</td>\n",
       "      <td>vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach Pesto with Seared Tomatoes and Shaved ...</td>\n",
       "      <td></td>\n",
       "      <td>vegetarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I attempted Yeast Free Naan! Paneer Masala and...   \n",
       "1                  Question about Vitamin A Palamite   \n",
       "2  Spinach Pesto with Seared Tomatoes and Shaved ...   \n",
       "\n",
       "                                            selftext   subreddit  \n",
       "0                                                     vegetarian  \n",
       "1  I've been vegetarian for a bit, and I know to ...  vegetarian  \n",
       "2                                                     vegetarian  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>PETA isn't the savior you think it is</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>It’s not racism or anything like that</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Could we be more of a plague to this planet?</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title   selftext subreddit\n",
       "9997         PETA isn't the savior you think it is                vegan\n",
       "9998         It’s not racism or anything like that  [removed]     vegan\n",
       "9999  Could we be more of a plague to this planet?                vegan"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new column named \"text\" to cover both \"title\" and \"seltext\" to fill more cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['title'] + ' ' + df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I attempted Yeast Free Naan! Paneer Masala and...</td>\n",
       "      <td></td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>I attempted Yeast Free Naan! Paneer Masala and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question about Vitamin A Palamite</td>\n",
       "      <td>I've been vegetarian for a bit, and I know to ...</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>Question about Vitamin A Palamite I've been ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spinach Pesto with Seared Tomatoes and Shaved ...</td>\n",
       "      <td></td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>Spinach Pesto with Seared Tomatoes and Shaved ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I attempted Yeast Free Naan! Paneer Masala and...   \n",
       "1                  Question about Vitamin A Palamite   \n",
       "2  Spinach Pesto with Seared Tomatoes and Shaved ...   \n",
       "\n",
       "                                            selftext   subreddit  \\\n",
       "0                                                     vegetarian   \n",
       "1  I've been vegetarian for a bit, and I know to ...  vegetarian   \n",
       "2                                                     vegetarian   \n",
       "\n",
       "                                                text  \n",
       "0  I attempted Yeast Free Naan! Paneer Masala and...  \n",
       "1  Question about Vitamin A Palamite I've been ve...  \n",
       "2  Spinach Pesto with Seared Tomatoes and Shaved ...  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Thought y’all might like this card :)</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "      <td>Thought y’all might like this card :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>I HATE VEGANS</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "      <td>I HATE VEGANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Coming this week at my Aldi only $3.99 for a p...</td>\n",
       "      <td></td>\n",
       "      <td>vegan</td>\n",
       "      <td>Coming this week at my Aldi only $3.99 for a p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title selftext subreddit  \\\n",
       "9997              Thought y’all might like this card :)              vegan   \n",
       "9998                                      I HATE VEGANS              vegan   \n",
       "9999  Coming this week at my Aldi only $3.99 for a p...              vegan   \n",
       "\n",
       "                                                   text  \n",
       "9997             Thought y’all might like this card :)   \n",
       "9998                                     I HATE VEGANS   \n",
       "9999  Coming this week at my Aldi only $3.99 for a p...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 20,000 observations and two equal calsses our DataFrame are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vegetarian    10000\n",
       "vegan         10000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"subreddit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our \"subreddit\" column with two equal categories should be converted into Boolean (binary labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"subreddit\"] = df[\"subreddit\"].map({\"vegetarian\": 1, \"vegan\": 0})\n",
    "df[\"subreddit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could our app help keeping your dieting style?</td>\n",
       "      <td>Hi,\\n\\nI’m a researcher at an early stage nutr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could our app help keeping your dieting style?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Craving</td>\n",
       "      <td>Hey I’ve tried going vegetarian at least 5/6 t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Craving Hey I’ve tried going vegetarian at lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anything to do to stop meat cravings?</td>\n",
       "      <td>I have been vegetarian (lacto-ovo, but on and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Anything to do to stop meat cravings? I have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Fried spicy sweet potato balls that became cubes   \n",
       "1     Could our app help keeping your dieting style?   \n",
       "2                                            Craving   \n",
       "3              Anything to do to stop meat cravings?   \n",
       "4  Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0                                                             1   \n",
       "1  Hi,\\n\\nI’m a researcher at an early stage nutr...          1   \n",
       "2  Hey I’ve tried going vegetarian at least 5/6 t...          1   \n",
       "3  I have been vegetarian (lacto-ovo, but on and ...          1   \n",
       "4                                                             1   \n",
       "\n",
       "                                                text  \n",
       "0  Fried spicy sweet potato balls that became cubes   \n",
       "1  Could our app help keeping your dieting style?...  \n",
       "2  Craving Hey I’ve tried going vegetarian at lea...  \n",
       "3  Anything to do to stop meat cravings? I have b...  \n",
       "4  Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Is OK to swallow after oral?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Would most vegans ridicule a person who choose...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>Would most vegans ridicule a person who choose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Thought y’all might like this card :)</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Thought y’all might like this card :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>I HATE VEGANS</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>I HATE VEGANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Coming this week at my Aldi only $3.99 for a p...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Coming this week at my Aldi only $3.99 for a p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title   selftext  subreddit  \\\n",
       "9995                       Is OK to swallow after oral?        NaN          0   \n",
       "9996  Would most vegans ridicule a person who choose...  [removed]          0   \n",
       "9997              Thought y’all might like this card :)                     0   \n",
       "9998                                      I HATE VEGANS                     0   \n",
       "9999  Coming this week at my Aldi only $3.99 for a p...                     0   \n",
       "\n",
       "                                                   text  \n",
       "9995                                                NaN  \n",
       "9996  Would most vegans ridicule a person who choose...  \n",
       "9997             Thought y’all might like this card :)   \n",
       "9998                                     I HATE VEGANS   \n",
       "9999  Coming this week at my Aldi only $3.99 for a p...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some statistical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean characters in text, Vegetarian subreddit: 318.42\n",
      "Median characters in text, Vegetarian subreddit: 253.0\n"
     ]
    }
   ],
   "source": [
    "# First subreddit Vegetarian,\n",
    "\n",
    "print('Mean characters in text, Vegetarian subreddit: ' + str(round(df.loc[df['subreddit'] == 1]['text'].str.len().mean(),2)))\n",
    "print('Median characters in text, Vegetarian subreddit: ' + str(round(df.loc[df['subreddit'] == 1]['text'].str.len().median(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean characters in text, Vegan subreddit: 318.42\n",
      "Median characters in text, Vegan subreddit: 253.0\n"
     ]
    }
   ],
   "source": [
    "# Second subreddit Vegan,\n",
    "\n",
    "print('Mean characters in text, Vegan subreddit: ' + str(round(df.loc[df['subreddit'] == 1]['text'].str.len().mean(),2)))\n",
    "print('Median characters in text, Vegan subreddit: ' + str(round(df.loc[df['subreddit'] == 1]['text'].str.len().median(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean characters in text: 299.29\n",
      "Median characters in text: 117.0\n"
     ]
    }
   ],
   "source": [
    "# Finally Mean + median text length,\n",
    "\n",
    "print('Mean characters in text: ' + str(round(df['text'].str.len().mean(),2)))\n",
    "print('Median characters in text: ' + str(round(df['text'].str.len().median(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"title\"].isin([\"Vegan\", , \"Vegetarian\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can save our data to csv,  Lesson  2.01 - intro to pandas, 0.13 Exporting Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\")\n",
    "df = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Could our app help keeping your dieting style?</td>\n",
       "      <td>Hi,\\n\\nI’m a researcher at an early stage nutr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could our app help keeping your dieting style?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Craving</td>\n",
       "      <td>Hey I’ve tried going vegetarian at least 5/6 t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Craving Hey I’ve tried going vegetarian at lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Anything to do to stop meat cravings?</td>\n",
       "      <td>I have been vegetarian (lacto-ovo, but on and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Anything to do to stop meat cravings? I have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0   Fried spicy sweet potato balls that became cubes   \n",
       "1           1     Could our app help keeping your dieting style?   \n",
       "2           2                                            Craving   \n",
       "3           3              Anything to do to stop meat cravings?   \n",
       "4           4  Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0                                                NaN          1   \n",
       "1  Hi,\\n\\nI’m a researcher at an early stage nutr...          1   \n",
       "2  Hey I’ve tried going vegetarian at least 5/6 t...          1   \n",
       "3  I have been vegetarian (lacto-ovo, but on and ...          1   \n",
       "4                                                NaN          1   \n",
       "\n",
       "                                                text  \n",
       "0  Fried spicy sweet potato balls that became cubes   \n",
       "1  Could our app help keeping your dieting style?...  \n",
       "2  Craving Hey I’ve tried going vegetarian at lea...  \n",
       "3  Anything to do to stop meat cravings? I have b...  \n",
       "4  Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could our app help keeping your dieting style?</td>\n",
       "      <td>Hi,\\n\\nI’m a researcher at an early stage nutr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could our app help keeping your dieting style?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Craving</td>\n",
       "      <td>Hey I’ve tried going vegetarian at least 5/6 t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Craving Hey I’ve tried going vegetarian at lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0  Fried spicy sweet potato balls that became cubes   \n",
       "1    Could our app help keeping your dieting style?   \n",
       "2                                           Craving   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0                                                NaN          1   \n",
       "1  Hi,\\n\\nI’m a researcher at an early stage nutr...          1   \n",
       "2  Hey I’ve tried going vegetarian at least 5/6 t...          1   \n",
       "\n",
       "                                                text  \n",
       "0  Fried spicy sweet potato balls that became cubes   \n",
       "1  Could our app help keeping your dieting style?...  \n",
       "2  Craving Hey I’ve tried going vegetarian at lea...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "selftext     10000\n",
       "subreddit        0\n",
       "text           800\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0.00\n",
       "selftext     0.50\n",
       "subreddit    0.00\n",
       "text         0.04\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We succesfully did collectig data for both of our subreddits and now we are ready to clean our data along doind EDA then move for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"subreddit\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some work on 'Null' values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"selftext\"].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "selftext     0\n",
       "subreddit    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Fried spicy sweet potato balls that became cubes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could our app help keeping your dieting style?</td>\n",
       "      <td>Hi,\\n\\nI’m a researcher at an early stage nutr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Could our app help keeping your dieting style?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Craving</td>\n",
       "      <td>Hey I’ve tried going vegetarian at least 5/6 t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Craving Hey I’ve tried going vegetarian at lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anything to do to stop meat cravings?</td>\n",
       "      <td>I have been vegetarian (lacto-ovo, but on and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Anything to do to stop meat cravings? I have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Fried spicy sweet potato balls that became cubes   \n",
       "1     Could our app help keeping your dieting style?   \n",
       "2                                            Craving   \n",
       "3              Anything to do to stop meat cravings?   \n",
       "4  Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0                                                             1   \n",
       "1  Hi,\\n\\nI’m a researcher at an early stage nutr...          1   \n",
       "2  Hey I’ve tried going vegetarian at least 5/6 t...          1   \n",
       "3  I have been vegetarian (lacto-ovo, but on and ...          1   \n",
       "4                                                             1   \n",
       "\n",
       "                                                text  \n",
       "0  Fried spicy sweet potato balls that became cubes   \n",
       "1  Could our app help keeping your dieting style?...  \n",
       "2  Craving Hey I’ve tried going vegetarian at lea...  \n",
       "3  Anything to do to stop meat cravings? I have b...  \n",
       "4  Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Is OK to swallow after oral?</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Would most vegans ridicule a person who choose...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>Would most vegans ridicule a person who choose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Thought y’all might like this card :)</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Thought y’all might like this card :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>I HATE VEGANS</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>I HATE VEGANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Coming this week at my Aldi only $3.99 for a p...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Coming this week at my Aldi only $3.99 for a p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title   selftext  \\\n",
       "19995                       Is OK to swallow after oral?              \n",
       "19996  Would most vegans ridicule a person who choose...  [removed]   \n",
       "19997              Thought y’all might like this card :)              \n",
       "19998                                      I HATE VEGANS              \n",
       "19999  Coming this week at my Aldi only $3.99 for a p...              \n",
       "\n",
       "       subreddit                                               text  \n",
       "19995          0                                                     \n",
       "19996          0  Would most vegans ridicule a person who choose...  \n",
       "19997          0             Thought y’all might like this card :)   \n",
       "19998          0                                     I HATE VEGANS   \n",
       "19999          0  Coming this week at my Aldi only $3.99 for a p...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d96dd49cc0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to see there is no \"null\" values in our data;\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df.isnull(), yticklabels = False, cbar = False, cmap = \"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        object\n",
       "selftext     object\n",
       "subreddit     int64\n",
       "text         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our X and y variables;\n",
    "\n",
    "features = \"text\"\n",
    "target = \"subreddit\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fried spicy sweet potato balls that became cubes \n",
       "1    Could our app help keeping your dieting style?...\n",
       "2    Craving Hey I’ve tried going vegetarian at lea...\n",
       "3    Anything to do to stop meat cravings? I have b...\n",
       "4    Vegan ahi \"tuna\" bowl [Shin Sen Gumi Hakata Ra...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19995    0\n",
       "19996    0\n",
       "19997    0\n",
       "19998    0\n",
       "19999    0\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To find some top words for both subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google, kdnuggles.com\n",
    "\n",
    "def get_top_n_words(corpus, n = None):\n",
    "    covec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = covec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis = 0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in covec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 vegeterian words (no stop words);\n",
    "\n",
    "top_vegi = get_top_n_words(df[df['subreddit'] == 1]['text'], 10)\n",
    "top_vegi = dict(top_vegi)\n",
    "top_vegi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 vegan words (no stop words);\n",
    "\n",
    "top_vegan = get_top_n_words(df[df['subreddit'] == 0]['text'], 10)\n",
    "top_vegan = dict(top_vegan)\n",
    "top_vegan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bar graph of top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of top 10 vegetarian tokens; \n",
    "\n",
    "# set the fig size;\n",
    "\n",
    "plt.figure(figsize = (14, 11))\n",
    "\n",
    "sns.barplot(x = list(top_vegi.keys()),y = list(top_vegi.values()))\n",
    "plt.title('Frequency of Top 10 Tokens in vegetarian_reddit', fontsize = 15)\n",
    "plt.xlabel('Tokens', fontsize = 12)\n",
    "plt.ylabel('Token Count',fontsize = 12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of top 10 vegan tokens;\n",
    "\n",
    "# set the fig size;\n",
    "\n",
    "plt.figure(figsize = (14, 11))\n",
    "\n",
    "sns.barplot(x = list(top_vegan.keys()), y = list(top_vegan.values()))\n",
    "plt.title('Frequency of Top 10 Tokens in vegan_reddit', fontsize = 15)\n",
    "plt.xlabel('Tokens',fontsize = 12)\n",
    "plt.ylabel('Token Count',fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model = CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CountVectorizer.\n",
    "\n",
    "covec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the vectorizer on our corpus.\n",
    "\n",
    "covec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the corpus.\n",
    "\n",
    "X_train = covec.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>99</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>acres</th>\n",
       "      <th>...</th>\n",
       "      <th>wraps</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  15  19  99  about  absolutely  abundance  abuse  accidentally  acres  \\\n",
       "0   0   0   0   0      0           0          0      0             0      0   \n",
       "1   2   0   0   0      0           0          0      0             0      0   \n",
       "2   0   0   0   0      0           0          0      0             0      0   \n",
       "3   0   0   0   0      0           0          0      0             0      0   \n",
       "4   0   0   0   0      0           1          0      0             0      0   \n",
       "\n",
       "   ...  wraps  wrong  wrote  www  year  years  yet  yogurt  you  your  \n",
       "0  ...      0      0      0    0     0      0    0       0    0     0  \n",
       "1  ...      0      0      0    0     0      1    0       0    0     0  \n",
       "2  ...      0      0      0    0     0      0    0       0    0     0  \n",
       "3  ...      0      0      0    0     0      0    0       0    0     0  \n",
       "4  ...      0      0      0    0     0      0    0       0    0     0  \n",
       "\n",
       "[5 rows x 868 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X_train into a DataFrame.\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train.toarray(),\n",
    "                          columns=covec.get_feature_names())\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the corpus.\n",
    "\n",
    "X_test = covec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>99</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>acres</th>\n",
       "      <th>...</th>\n",
       "      <th>wraps</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  15  19  99  about  absolutely  abundance  abuse  accidentally  acres  \\\n",
       "0   0   0   0   0      0           0          0      0             0      0   \n",
       "1   0   0   0   0      0           0          0      0             0      0   \n",
       "2   0   0   0   0      0           0          0      0             0      0   \n",
       "3   0   0   0   0      0           0          0      0             0      0   \n",
       "4   0   0   0   0      0           0          0      0             0      0   \n",
       "\n",
       "   ...  wraps  wrong  wrote  www  year  years  yet  yogurt  you  your  \n",
       "0  ...      0      0      0    0     0      1    0       0    2     0  \n",
       "1  ...      0      0      0    1     0      0    0       0    0     0  \n",
       "2  ...      0      0      0    0     0      0    0       0    1     0  \n",
       "3  ...      0      0      0    0     0      0    0       0    0     0  \n",
       "4  ...      0      0      0    0     0      0    0       0    5     1  \n",
       "\n",
       "[5 rows x 868 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform test\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test.toarray(),\n",
    "                         columns=covec.get_feature_names())\n",
    "\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'get', 'being', 'for', 'together', 'wherever', 'must', 'me', 'off', 'we', 'in', 'yourselves', 'with', 'also', 'per', 'beyond', 'either', 'so', 'never', 'am', 'whereas', 'on', 'have', 'front', 'inc', 'it', 'been', 'beforehand', 'she', 'take', 'whereafter', 'beside', 'what', 'but', 'everything', 'would', 'are', 'both', 'fill', 'nobody', 'etc', 'hundred', 'back', 'will', 'your', 'four', 'name', 'amongst', 'former', 'found', 'becomes', 'enough', 'somewhere', 'fifty', 'his', 'same', 'until', 'eleven', 'seem', 'next', 'own', 'move', 'thus', 'hence', 'fire', 'afterwards', 'and', 'less', 'done', 'others', 'least', 'such', 'below', 'show', 'again', 'amount', 'side', 'someone', 'though', 'her', 'mostly', 'any', 'whoever', 'part', 'another', 'hereby', 'wherein', 'describe', 'several', 'or', 'onto', 'noone', 'sincere', 'some', 'since', 'there', 'anyhow', 'our', 'call', 're', 'whom', 'many', 'two', 'therefore', 'already', 'mine', 'their', 'thereafter', 'made', 'three', 'they', 'no', 'give', 'herein', 'nor', 'these', 'ourselves', 'sixty', 'who', 'sometimes', 'after', 'except', 'interest', 'of', 'thereupon', 'much', 'sometime', 'please', 'nevertheless', 'formerly', 'everyone', 'anywhere', 'down', 'indeed', 'into', 'those', 'before', 'nowhere', 'against', 'too', 'still', 'above', 'over', 'by', 'hers', 'might', 'find', 'however', 'behind', 'thin', 'often', 'top', 'something', 'system', 'somehow', 'mill', 'latter', 'themselves', 'at', 'be', 'eg', 'becoming', 'an', 'alone', 'thereby', 'then', 'namely', 'every', 'once', 'its', 'anyone', 'between', 'during', 'rather', 'within', 'should', 'out', 'yet', 'is', 'meanwhile', 'otherwise', 'nine', 'hereupon', 'nothing', 'that', 'about', 'when', 'whither', 'among', 'besides', 'could', 'un', 'fifteen', 'were', 'had', 'to', 'can', 'therein', 'whole', 'seems', 'anyway', 'go', 'thru', 'very', 'yourself', 'cannot', 'itself', 'along', 'latterly', 'cry', 'bill', 'hasnt', 'seeming', 'almost', 'few', 'twenty', 'one', 'ltd', 'herself', 'the', 'anything', 'has', 'else', 'whenever', 'forty', 'detail', 'became', 'elsewhere', 'via', 'my', 'where', 'this', 'across', 'as', 'toward', 'upon', 'whatever', 'thence', 'de', 'moreover', 'whereby', 'whereupon', 'him', 'most', 'ie', 'each', 'seemed', 'always', 'eight', 'because', 'a', 'due', 'i', 'whether', 'first', 'himself', 'around', 'five', 'through', 'which', 'more', 'other', 'amoungst', 'last', 'empty', 'here', 'from', 'co', 'than', 'all', 'put', 'only', 'cant', 'them', 'whose', 'he', 'towards', 'further', 'how', 'six', 'twelve', 'myself', 'may', 'yours', 'well', 'you', 'ten', 'bottom', 'hereafter', 'not', 'while', 'although', 'up', 'ours', 'whence', 'ever', 'serious', 'become', 'con', 'everywhere', 'third', 'why', 'full', 'now', 'neither', 'keep', 'even', 'see', 'thick', 'without', 'couldnt', 'was', 'do', 'none', 'if', 'us', 'perhaps', 'under', 'throughout'})\n"
     ]
    }
   ],
   "source": [
    "# Let's look at sklearn's stopwords.\n",
    "\n",
    "print(CountVectorizer(stop_words = 'english').get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine training and testing sets.\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "#                                                     y,\n",
    "#                                                     test_size=0.33,\n",
    "#                                                     stratify=y,\n",
    "#                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. LogisticRegression (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('covec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver = 'lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the lesson;\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'covec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'covec__min_df': [2, 3],\n",
    "    'covec__max_df': [.9, .95],\n",
    "    'covec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe,                              # what object are we optimizing?\n",
    "                  param_grid = pipe_params,          # what parameters values are we searching?\n",
    "                  cv = 5)                            # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('covec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u...\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'covec__max_df': [0.9, 0.95],\n",
       "                         'covec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'covec__min_df': [2, 3],\n",
       "                         'covec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802142857142856\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model as gs_model.\n",
    "\n",
    "gs_covec = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802142857142857"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "\n",
    "gs_covec.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "\n",
    "gs_covec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802141987714856"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X_train, y_train, cv = 3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802142857142857"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_bl = gs.best_estimator_\n",
    "logreg_bl.fit(X_train, y_train)\n",
    "\n",
    "logreg_bl.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_bl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model = TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the transformer.\n",
    "\n",
    "tf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>99</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>acres</th>\n",
       "      <th>...</th>\n",
       "      <th>wraps</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.474471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10   15   19   99  about  absolutely  abundance  abuse  accidentally  \\\n",
       "0  0.000000  0.0  0.0  0.0    0.0    0.000000        0.0    0.0           0.0   \n",
       "1  0.474471  0.0  0.0  0.0    0.0    0.000000        0.0    0.0           0.0   \n",
       "2  0.000000  0.0  0.0  0.0    0.0    0.000000        0.0    0.0           0.0   \n",
       "3  0.000000  0.0  0.0  0.0    0.0    0.000000        0.0    0.0           0.0   \n",
       "4  0.000000  0.0  0.0  0.0    0.0    0.197909        0.0    0.0           0.0   \n",
       "\n",
       "   acres  ...  wraps  wrong  wrote  www  year     years  yet  yogurt  you  \\\n",
       "0    0.0  ...    0.0    0.0    0.0  0.0   0.0  0.000000  0.0     0.0  0.0   \n",
       "1    0.0  ...    0.0    0.0    0.0  0.0   0.0  0.151131  0.0     0.0  0.0   \n",
       "2    0.0  ...    0.0    0.0    0.0  0.0   0.0  0.000000  0.0     0.0  0.0   \n",
       "3    0.0  ...    0.0    0.0    0.0  0.0   0.0  0.000000  0.0     0.0  0.0   \n",
       "4    0.0  ...    0.0    0.0    0.0  0.0   0.0  0.000000  0.0     0.0  0.0   \n",
       "\n",
       "   your  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 868 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tf_vec.fit_transform(X_train).toarray(), columns = tf_vec.get_feature_names())\n",
    "                  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf_vec.fit_transform(X_train)\n",
    "\n",
    "X_test = tf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9802142857142857\n",
      "Testing Score: 0.9795\n"
     ]
    }
   ],
   "source": [
    "# Instantiate logistic regression.\n",
    "\n",
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# Fit logistic regression.\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate logistic regression.\n",
    "\n",
    "print(f'Training Score: {logreg.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {logreg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate and show classification metrics,\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def class_metrics(model, X, y): \n",
    "    \n",
    "    # Generate predictions\n",
    "    \n",
    "    preds = model.predict(X)\n",
    "    \n",
    "    # Get confusion matrix and unravel\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y,preds).ravel()\n",
    "    \n",
    "    # Accuracy\n",
    "    \n",
    "    print(f'Accuracy: {round((tp + tn)/len(y),3)}')\n",
    "    \n",
    "    # Sensitivity or Recall\n",
    "    \n",
    "    print(f'Sensitivity: {round(tp /(tp + fn),3)}')\n",
    "    \n",
    "    # Specificity\n",
    "    \n",
    "    print(f'Specificity: {round(tn / (tn + fp),3)}')\n",
    "    \n",
    "    # Precision\n",
    "    \n",
    "    print(f'Precision: {round(tp / (tp + fp),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and CountVectorizer Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipleline, \"c\" represents CounterVectorizer;\n",
    "\n",
    "c_pipe = Pipeline([\n",
    "    ('covec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver = 'liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe parameters, \"c\" represents CounterVectorizer;\n",
    "\n",
    "c_pipe_params = {\n",
    "    'covec__max_features': [100, 500],\n",
    "    'covec__stop_words': [None, 'english'],\n",
    "    'covec__ngram_range': [(1,1), (1,2)],\n",
    "    'logreg__C': [0.1, 1, 1e9],\n",
    "    'logreg__penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_features': 500, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None, 'logreg__C': 0.1, 'logreg__penalty': 'l1'}\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 0.959\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV, \"c\" represents CounterVectorizer; \n",
    "\n",
    "c_gs = GridSearchCV(c_pipe, c_pipe_params, cv = 5, n_jobs = 2)\n",
    "\n",
    "# Fit;\n",
    "\n",
    "c_gs.fit(X_train,y_train);\n",
    "\n",
    "# Show metrics and best parameters;\n",
    "\n",
    "print(c_gs.best_params_)\n",
    "class_metrics(c_gs,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Sensitivity: 0.96\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "class_metrics(c_gs,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and TfidfVectorizer Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipleline;\n",
    "\n",
    "lr_tf_pipe = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('logreg',LogisticRegression(solver = 'liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe parameters;\n",
    "\n",
    "lr_tf_pipe_params = {\n",
    "    'tfidf__max_features': [100, 500],\n",
    "    'tfidf__stop_words': [None,'english'],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'logreg__C': [0.1, 1, 1e9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf grid search\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "lr_tf_gs = GridSearchCV(lr_tf_pipe, \n",
    "                    lr_tf_pipe_params, \n",
    "                    cv = 5,\n",
    "                    n_jobs = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 0.1, 'tfidf__max_features': 500, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 0.959\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Fit grid search;\n",
    "\n",
    "lr_tf_gs.fit(X_train,y_train);\n",
    "\n",
    "\n",
    "# Show metrics and best parameters;\n",
    "\n",
    "print(lr_tf_gs.best_params_)\n",
    "class_metrics(lr_tf_gs,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Sensitivity: 0.96\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "class_metrics(lr_tf_gs,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer and the Multinomial Naive Bayes estimator\n",
    "\n",
    "**NOTE**: Remember lab information that why we use Multinomial Naive Bayes, because our nonnegative integers values. CounterVectorizer transforms our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv = Pipeline([\n",
    "    ('vec',CountVectorizer()),\n",
    "    ('estimator', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'vec__max_features':[1000, 2000, 5000],\n",
    "    'vec__min_df':[2, 3],\n",
    "    'vec__max_df':[0.90, 0.95, 1.0],\n",
    "    'vec__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: We need to apply GridSearchCV to find the best parameters, because we need to tune our CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674.4819326400757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "t_0 = time.time()\n",
    "\n",
    "gs_cv = GridSearchCV(pipe_cv,\n",
    "                     pipe_params,\n",
    "                     cv = 5,\n",
    "                     n_jobs = -1                     \n",
    "                 )\n",
    "gs_cv.fit(X_train, y_train)\n",
    "\n",
    "print(time.time() - t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the lesson;\n",
    "\n",
    "# Import Tokenizer\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Instantiate Tokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# \"Run\" Tokenizer\n",
    "\n",
    "spam_tokens = tokenizer.tokenize(spam.lower())\n",
    "\n",
    "# Import stemmer.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Instantiate object of class PorterStemmer.\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# Stem tokens.\n",
    "\n",
    "stem_spam = [p_stemmer.stem(i) for i in spam_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PorterStemmer - CoVec\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "covec_analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def porter_covec_words(doc):\n",
    "    return (p_stemmer.stem(word) for word in covec_analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNetLemmatizer - CoVec\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_covec_words(doc):\n",
    "    return (lemmatizer.lemmatize(word) for word in covec_analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - CountVectorizer Transformation AND ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipleline\n",
    "pipe_ct = Pipeline([\n",
    "    ('covec',CountVectorizer()),\n",
    "    ('logreg',LogisticRegression(solver = 'liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe parameters\n",
    "pipe_ct_params = {\n",
    "    'covec__max_features': [100, 500],\n",
    "    'covec__stop_words': [None,'english'],\n",
    "    'covec__ngram_range': [(1,1), (1,2)],\n",
    "    'covec__analyzer': ['word', porter_covec_words, lemmatizer_covec_words],\n",
    "    'logreg__C': [0.1, 1, 1e9],\n",
    "    'logreg__penalty': ['l1','l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'covec__analyzer': 'word', 'covec__max_features': 500, 'covec__ngram_range': (1, 1), 'covec__stop_words': None, 'logreg__C': 0.1, 'logreg__penalty': 'l1'}\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 0.959\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV;\n",
    "\n",
    "gs_ct = GridSearchCV(pipe_ct, pipe_ct_params, cv = 5, n_jobs = 2)\n",
    "\n",
    "# Fit;\n",
    "\n",
    "gs_ct.fit(X_train, y_train);\n",
    "\n",
    "# Show metrics and best parameters;\n",
    "\n",
    "print(gs_ct.best_params_)\n",
    "class_metrics(gs_ct, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Sensitivity: 0.96\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "class_metrics(gs_ct, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: It seems we get  great result. Accuracy is really high. Classification metrics are good at score. Specifity and sensitivity scores are so close and the gap is not much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - TfidfVectorizer Transformation AND ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PorterStemmer - TfIdf;\n",
    "\n",
    "tf_idf_analyzer = TfidfVectorizer().build_analyzer()\n",
    "\n",
    "def porter_tfidf_words(doc):\n",
    "    return (p_stemmer.stem(word) for word in tf_idf_analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNetLemmatizer - TfIdf;\n",
    "\n",
    "def lemmatizer_tfidf_words(doc):\n",
    "    return (lemmatizer.lemmatize(word) for word in tf_idf_analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipleline;\n",
    "\n",
    "pipe_tfc = Pipeline([\n",
    "    ('tf_idf',TfidfVectorizer(analyzer = porter_tfidf_words)),\n",
    "    ('logreg',LogisticRegression(solver = 'liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe parameters;\n",
    "\n",
    "pipe_tfc_params = {\n",
    "    'tf_idf__max_features': [100, 500],\n",
    "    'tf_idf__stop_words': [None,'english'],\n",
    "    'tf_idf__ngram_range': [(1,1), (1,2)],\n",
    "    'logreg__C': [0.1, 1, 1e9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 0.1, 'tf_idf__max_features': 500, 'tf_idf__ngram_range': (1, 1), 'tf_idf__stop_words': None}\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 0.959\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# tf_idf grid search\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tfc = GridSearchCV(pipe_tfc, pipe_tfc_params,  cv = 5,  n_jobs = 2) \n",
    "\n",
    "# Fit grid search;\n",
    "\n",
    "gs_tfc.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "# Show metrics and best parameters;\n",
    "\n",
    "print(gs_tfc.best_params_)\n",
    "class_metrics(gs_tfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Sensitivity: 0.96\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "class_metrics(gs_tfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802141987714856"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe_tfc, X_train, y_train, cv = 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation X to work on $k$-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer model,    # Instantiate THE model;\n",
    "# represent by    \"Z\";\n",
    "\n",
    "covec = CountVectorizer(analyzer = porter_covec_words, max_features = 500)\n",
    "\n",
    "# Fit the model;\n",
    "\n",
    "covec.fit(X_train)\n",
    "\n",
    "# Transform;\n",
    "\n",
    "Z_train = covec.transform(X_train)\n",
    "Z_test = covec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe;   represent by \"Z\";\n",
    "\n",
    "Z_train = pd.DataFrame(Z_train.toarray(), columns = covec.get_feature_names())\n",
    "Z_test = pd.DataFrame(Z_test.toarray(), columns = covec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer model,   # Instantiate the model;   represent by \"T\";\n",
    "\n",
    "tf_idf_t = TfidfVectorizer(analyzer = porter_covec_words, max_features = 500)\n",
    "\n",
    "# Fit the model;\n",
    "\n",
    "tf_idf_t.fit(X_train)\n",
    "\n",
    "# Transform;\n",
    "\n",
    "T_train = tf_idf_t.transform(X_train)\n",
    "T_test = tf_idf_t.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe;     represent by \"T\";\n",
    "\n",
    "T_train = pd.DataFrame(T_train.toarray(), columns = tf_idf_t.get_feature_names())\n",
    "T_test = pd.DataFrame(T_test.toarray(), columns = tf_idf_t.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model: $K$NN -  Transformation: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe parameters;\n",
    "\n",
    "knn_ct_params = {\n",
    "    'n_neighbors': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV;\n",
    "\n",
    "knn_ct_gs = GridSearchCV(KNeighborsClassifier(),  knn_ct_params, cv = 5, n_jobs = 2)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data;\n",
    "\n",
    "st_sc = StandardScaler()\n",
    "Z_train_sc = st_sc.fit_transform(Z_train)\n",
    "Z_test_sc = st_sc.transform(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit;\n",
    "\n",
    "knn_ct_gs.fit(Z_train_sc, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter: {'n_neighbors': 1}\n",
      "\n",
      "Training Scores\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.96\n",
      "Precision: 0.962\n",
      "\n",
      "Test Scores\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.959\n",
      "Precision: 0.961\n"
     ]
    }
   ],
   "source": [
    "# Show metrics and best parameters; \n",
    "\n",
    "print(f'Best hyperparameter: {knn_ct_gs.best_params_}\\n')\n",
    "print('Training Scores')\n",
    "class_metrics(knn_ct_gs, Z_train_sc, y_train)\n",
    "\n",
    "print('\\nTest Scores')\n",
    "class_metrics(knn_ct_gs, Z_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The result of $k$-nn model is also good. Sensitivity score is a little more than specificity score and it is a success to calassify vegetarian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model: $K$NN -  Transformation: TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter: {'n_neighbors': 25}\n",
      "\n",
      "Training Scores\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 0.96\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "\n",
      "Test Scores\n",
      "Accuracy: 0.98\n",
      "Sensitivity: 0.959\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# GridSearch parameters;\n",
    "\n",
    "knn_tf_idft_params = {\n",
    "    'n_neighbors': [5,15,25]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV;\n",
    "\n",
    "knn_tf_idft_gs = GridSearchCV(KNeighborsClassifier(), knn_tf_idft_params, cv = 5, n_jobs = 2) \n",
    "\n",
    "# Fit;\n",
    "\n",
    "knn_tf_idft_gs.fit(T_train, y_train);\n",
    "\n",
    "# Show metrics and best parameters;\n",
    "\n",
    "print(f'Best hyperparameter: {knn_tf_idft_gs.best_params_}\\n')\n",
    "\n",
    "print('Training Scores')\n",
    "class_metrics(knn_tf_idft_gs, T_train, y_train)\n",
    "\n",
    "print('\\nTest Scores')\n",
    "class_metrics(knn_tf_idft_gs, T_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([(\"covec\", CountVectorizer),\n",
    "                    (\"st_sc\", st_sc),\n",
    "                    (\"knn\", KNeighborsClassifier),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn_params = {\n",
    "    'covec__max_features': [3_000, 5_000, 7_500],\n",
    "    'covec__min_df': [2, 5, 10],\n",
    "    'knn_n_neighbors': [1, 3, 5],\n",
    "    'covec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_knn = GridSearchCV(pipe_knn,                  # what object are we optimizing?\n",
    "                  param_grid = pipe_knn_params,        # what parameters values are we searching?\n",
    "                  cv = 5,                              # 5-fold cross-validation.\n",
    "                  verbose = 10)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reza\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "AttributeError: 'Series' object has no attribute '_validate_params'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "print(f\"CV score mean:{cross_val_score(pipe_knn, X_train, y_train, cv = 5).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Naive Bayes , Multinomial Naive Bayes Model - CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Multinomial Naive Bayes is appropriate when our features are variables that take on only positive integer counts which means CountVectorizer gives us an integer count of words in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.919\n",
      "Sensitivity: 0.918\n",
      "Specificity: 0.919\n",
      "Precision: 0.919\n",
      "\n",
      "Test Scores\n",
      "Accuracy: 0.923\n",
      "Sensitivity: 0.924\n",
      "Specificity: 0.922\n",
      "Precision: 0.922\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model;\n",
    "\n",
    "multi_nb = MultinomialNB()\n",
    "\n",
    "# Fit;\n",
    "\n",
    "multi_nb.fit(Z_train, y_train)\n",
    "\n",
    "# Metrics;\n",
    "\n",
    "print('Training Scores')\n",
    "class_metrics(multi_nb, Z_train, y_train)\n",
    "\n",
    "print('\\nTest Scores')\n",
    "class_metrics(multi_nb, Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187142857142857"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb.score(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: I think in this model it seems there is no overfitting and all score are acceptable. The difference between Sensitivity and Specificity score is 0.2 % which means it is about 0.002 better at classifying the vegeterian subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Naive Bayes , Gaussian Naive Bayes Model - TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:  It is appropriate when our features are Normally distributed variables. (Realistically, though, we kind of use Gaussian whenever neither Bernoulli nor Multinomial works.) It is not binary form and we can not use Bernoulli Naive Bayes because Bernoulli Naive Bayes is appropriate when our features are all 0/1 variables. We can not use Multinomial Naive Bayes because\n",
    "Multinomial Naive Bayes is appropriate when our features are variables that take on only positive integer counts. Then we fit Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.962\n",
      "Sensitivity: 0.924\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "\n",
      "Test Scores\n",
      "Accuracy: 0.956\n",
      "Sensitivity: 0.912\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model;\n",
    "\n",
    "gauss_nb = GaussianNB()\n",
    "\n",
    "# Fit the model;\n",
    "\n",
    "gauss_nb.fit(Z_train, y_train)\n",
    "\n",
    "# Metrics;\n",
    "\n",
    "print('Training Scores')\n",
    "class_metrics(gauss_nb, T_train, y_train)\n",
    "\n",
    "print('\\nTest Scores')\n",
    "class_metrics(gauss_nb, T_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9617857142857142"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_nb.score(T_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558333333333333"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_nb.score(T_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**:In this model I think NOT missing any vegan posts and classifying at vegetarian is good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Random Forest - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ft = RandomForestClassifier(random_state = 42)\n",
    "rand_ft_params = {\n",
    "    'n_estimators': [100, 125],\n",
    "    'max_depth': [None, 10, 25, 50],\n",
    "    'max_features': [None, 'auto']                  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ft_gs = GridSearchCV(rand_ft, rand_ft_params, cv = 5, n_jobs = 2)\n",
    "            \n",
    "rand_ft_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show metrics and best parameters;\n",
    "\n",
    "print(f'Best hyperparameter: {rand_ft_gs.best_params_}\\n')\n",
    "\n",
    "print('Training Scores')\n",
    "class_metrics(rand_ft_gs, Z_train, y_train)\n",
    "\n",
    "print('\\nTest Scores')\n",
    "class_metrics(rand_ft_gs, Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: I worked on different models where I can move on them with other conditions. it is possible to get a lot of great scores to get a good result. I prefer to say all models gave good result and scores were acceptabe.\n",
    "I need more time to work enough to create a model then I am looking for a model that performs a high accuracy and an optimization for our sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**:\n",
    "Sensitivity measures how often a test correctly generates a positive result for people who have the condition that’s being tested for (also known as the “true positive” rate).\n",
    "Specificity measures a test’s ability to correctly generate a negative result for people who don’t have the condition that’s being tested for (also known as the “true negative” rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
